{
  "metadata": {
    "file_extension": ".py",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "mimetype": "text/x-python",
    "name": "python",
    "npconvert_exporter": "python",
    "pygments_lexer": "ipython3",
    "version": 3
  },
  "nbformat": 4,
  "nbformat_minor": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# What is probability?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Suppose you were to flip a coin. Then you expect not to be able to say whether the next toss would yield a heads or a tails.  You might tell a friend that the odds of getting a heads is equal to to the odds of getting a tails, and that both are $1/2$.\n",
        "\n",
        "This intuitive notion of odds is a **probability**. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Probability as symmetry, or from a model\n",
        "\n",
        "### Symmetry\n",
        "\n",
        "Consider another example. If we were tossing a 'fair' six-sided dice, we may thus equivalently say that the odds of the dice falling on any one of its sides is $1/6$. Indeed if there are $C$ different equally likely possibilities, we'd expect that the probability of any one particular outcome would be $1/C$.\n",
        "\n",
        "The examples of the coin as well as the dice illustrate the notion of probability springing from **symmetry**. Here we think of probability of of the number 4 on the dice as the ratio:\n",
        "\n",
        "$$\\frac{Number\\: of\\: cases\\: for\\: number\\: 4}{number\\: of\\: possibilities} = \\frac{1}{6},$$\n",
        " assuming equally likely possibilities.\n",
        "\n",
        "\n",
        "\n",
        "### From a model\n",
        "\n",
        "But now think of an event like an election, say a presidential election. You cant exactly run multiple trials of the election: its a one-off event. But you still want to talk about the likelihood of a candidate winning. However people do make **models** of elections, based on inputs such as race, age, income, sampling polls, etc. They assign likeyhoods of candidates winning and run large numbers of **simulations** of the election, making predictions based on that. \n",
        "\n",
        "Or consider what a weather forecaster means when he or she says there is a 90% chance of rain today. Presumably, this conclusion has been made from many computer **simulations** which take in the weather conditions known in the past, and propagated using physics to the current day. The simulations give different results based on the uncertainty in the measurement of past weather, and the inability of the physics to capture the phenomenon exactly (all physics is some approximation to the natural world). But 90% of these simulations show rain.\n",
        "\n",
        "In all of these cases, there is either a model (a fair coin, an election forecasting model, a weather differential equation), or an experiment ( a large number of coin tosses) that is used to **estimate** a probability, or the odds, of an **event** $E$ occuring. \n",
        "\n",
        "## Probability as frequency\n",
        "\n",
        "The example above of doing multiple symbols has the feel of defining probability in terms of frequency, even if the frequency is in terms of simulations run in code on a computer.\n",
        "\n",
        "Consider doing a large number of coin flips. You would do, or imagine doing, a large number of flips or **trials** $N$, and finding the number of times you got heads $N_H$. Then the probability of getting heads would be \n",
        "$$\\frac{N_H}{N}.$$\n",
        "\n",
        "This is the notion of probability as a **relative frequency**: if there are multiple ways an **event** like the tossing of a coin can happen, lets look at multiple trials of the event and see the fraction of times one or other of these ways happened. \n",
        "\n",
        "This jibes with our general notion of probability from symmetry: indeed you can think of it as an experimental verification of a symmetry based model.\n",
        "\n",
        "We can test the model of a fair coin by having carried out a large number of coin flips. You would do, or imagine doing, a large number of flips or **trials** $N$, and finding the number of times you got heads $N_H$. Then the probability of getting heads would be \n",
        "$$\\frac{N_H}{N}.$$\n",
        "\n",
        "### Simulating the results of the model\n",
        "\n",
        "We dont have a coin right now. So let us **simulate** this process on a computer. To do this we will use a form of the **random number generator** built into `numpy`. In particular, we will use the function `np.random.choice`, which will with equal probability for all items pick an item from a list (thus if the list is of size 6, it will pick one of the six list items each time, with a probability 1/6)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "def throw_a_coin(N):\n",
        "    return np.random.choice(['H','T'], size=N)\n",
        "throws=throw_a_coin(40)\n",
        "print(\"Throws:\",\" \".join(throws))\n",
        "print(\"Number of Heads:\", np.sum(throws=='H'))\n",
        "print(\"p1 = Number of Heads/Total Throws:\", np.sum(throws=='H')/40.)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Notice that you do not necessarily get 20 heads.\n",
        "\n",
        "Now say that we run the entire process again, a second **replication** to obtain a second sample. Then we ask the same question: what is the fraction of heads we get this time? Lets call the odds of heads in sample 2, then, $p_2$:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "def make_throws(N):\n",
        "    throws=throw_a_coin(N)\n",
        "    if N <= 100:\n",
        "        print(\"Throws:\",\" \".join(throws))\n",
        "    else:\n",
        "        print(\"First 100 Throws:\",\" \".join(throws[:100]))\n",
        "    print(\"Number of Heads:\", np.sum(throws=='H'))\n",
        "    print(\"p1 = Number of Heads/Total Throws:\", np.sum(throws=='H')/N)\n",
        "make_throws(40)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Our intuitive notion is that as we do many more trials, we should find half the tosses being heads"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "make_throws(1000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "make_throws(10000)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "As you can see, the larger number of trials we do, the closer we seem to get to half the tosses showing up heads. Lets see this more systematically:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "trials=np.arange(0, 40000, 1000)\n",
        "plt.figure(figsize=(9,6))\n",
        "plt.plot(trials, [np.sum(throw_a_coin(j)=='H')/np.float(j) for j in trials], 'o-', alpha=0.2);\n",
        "plt.axhline(0.5, 0, 1, color='r');\n",
        "plt.xlabel('number of trials');\n",
        "plt.ylabel('probability of heads from simulation');\n",
        "plt.title('frequentist probability of heads');"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Thus, the true odds **fluctuate** about their long-run value of 0.5, in accordance with the model of a fair coin (which we encoded in our simulation by having `np.random.choice` choose between two possibilities with equal probability), with the fluctuations becoming much smaller. These **fluctations** are what give rise to probability distributions.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Thus, even a probability is not simply a probability. It comes with a distribution which depends on how many \"tosses\" or \"throws\" we have in our sample.\n",
        "\n",
        "The distribution for each toss is called the **Bernoulli** distribution, "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## A Simple Election Model\n",
        "\n",
        "Let us import data that contains a table of probabilities that PredictWise made on October 2, 2012 for the US presidential elections. PredictWise aggregated polling data and, for each state, estimated the probability that Obama or Romney would win. We import the required libraries first."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd # imports a library to handle data as dataframe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [],
      "source": [
        "predictwise = pd.read_csv('data/predictwise.csv').set_index('States')\n",
        "predictwise.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Each row is the probability predicted by Predictwise that Romney or Obama would win a state. The votes column lists the number of electoral college votes in that state.\n",
        "\n",
        "In the case of tossed coins, even though we have a model which says that the probability of heads is 0.5, there are sequences of flips in which more or less than half the flips were heads. Similarly, here, if the probability of Romney winning in Arizona is 0.938, it means that if somehow, there were 1000 replications with an election each, Romney would win in 938 of those Arizonas **on the average** across the replications. And there would be some samples with Romney winning more, and some with less. We can run these **simulated** universes on a computer though not in real life.\n",
        "\n",
        "How did these probabilities come about. It does not matter. I might have fit a deep neural network, a bayesian model, or just asked people to bet (thats what predictwise did). Its all just a model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Single simulation for a particular state\n",
        "\n",
        "Let us consider the sixth state, `Colorado` and do one random simulation for this state. We use the function `np.random.uniform` to draw 1 sample from a uniform distribution of interval \\[a,b) with an equal probability. The default values of a and b is \\[0,1). Documentation about the function [here](https://docs.scipy.org/doc/numpy-1.15.0/reference/generated/numpy.random.uniform.html)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Uniform Distribution (in numpy)\n",
        "\n",
        "`np.random.uniform` gives you a random number between 0 and 1, uniformly. In other words, the number is equally likely to be between 0 and 0.1, 0.1 and 0.2, and so on. This is a very intuitive idea, but it is formalized by the notion of the **Uniform Distribution**.\n",
        "\n",
        "We then say:\n",
        "\n",
        "$$X \\sim Uniform([0,1),$$\n",
        "\n",
        "which is to be read as **X has distribution Uniform([0,1])**. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(predictwise.loc['Colorado'])\n",
        "sim = np.random.uniform()\n",
        "print(sim)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Obama would would win Colorado for this particular simulation if his probability is higher than the random uniform number between 0 and 1. With and Obama probability of 0.807, Obama wins in this particular case."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [],
      "source": [
        "obama_win = (predictwise.loc['Colorado'].Obama > sim)*1\n",
        "print(obama_win)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Run this cell many times:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [],
      "source": [
        "obama_win = (predictwise.loc['Colorado'].Obama > np.random.uniform())*1\n",
        "print(obama_win)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Using `np.random.uniform` and comparing it to a probability threshold to get a 0 or 1 - this is nothing but a **Bernoulli Random Variable** for Colorado state.\n",
        "\n",
        "A Bernoulli Random Variable is the simplest kind of random variable. It can take on two values,\n",
        "1 and 0. It takes on a 1 if an experiment with probability *p* resulted in success and a 0 otherwise. A coin toss is another example of a Bernoulli Random Variable.  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "What assigning the vote to Obama when the random variable **drawn** from the Uniform distribution is less than the Predictwise probability of Obama winning (which is a Bernoulli Parameter) does for us is this: lets say we have a large number of simulations and $p_{Obama}=0.8$. Now if we draw lots of numbers between 0 and 1, uniformly, then 80\\% of the time, the random numbes drawn will be below 0.8. Thus we will now have many simulations with Obama either winning or losing, but winning about 80% of the time."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Multiple simulations for a particular State\n",
        "\n",
        "Now let's try and make 1000 simulations for Colorado. This is like making 1000 coin tosses with a biased coin. We expect Obama to win in about 80% of these"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(predictwise.loc['Colorado'])\n",
        "sims = np.random.uniform(size=1000)\n",
        "print(sims[:100])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "With an Obama probability of about 0.8, This means that we can pick the simulations in which Obama wins Colorado by seeing in how many of the simulations the random number thrown is less than 0.8\n",
        "\n",
        "We are simply making use of numpy broadcasting semantics here:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {},
      "outputs": [],
      "source": [
        "wins = sims < predictwise.loc['Colorado'].Obama\n",
        "wins[:100]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This is a boolean numpy array. Summing coerces the True to 1 and False to 0 and gives us the total number of simulations.<br>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {},
      "outputs": [],
      "source": [
        "np.sum(wins)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Obama wins in 81% of the simulations, roughly, in Colorado"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## The sources of Stochasticity"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In any model, there are multiple sources of stochasticity and error. Elections help us understand some of these.\n",
        "\n",
        "Lets ask where probabilities get their error from.\n",
        "\n",
        "### Sampling error\n",
        "\n",
        "Predictwise could not be asking too many bettors. Thus there is some sampling error in their probability estimates. They might have asked 1000 people who will win, and reported the frquencies as probabilities. But is they had asked another 1000 people, their answers would be somewhat different. This kind of error is called sampling error."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This kind of error can easily be demonstrated in coin tosses as well. So far we just did one run of tosses, (or for that matter, one tun of simulations). But imagine we had an infinite sequence of tosses and chose 500 toss samples from these. What fraction of these would be heads?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {},
      "outputs": [],
      "source": [
        "def make_throws(number_of_samples, sample_size):\n",
        "    start=np.zeros((number_of_samples, sample_size), dtype=int)\n",
        "    for i in range(number_of_samples):\n",
        "        start[i,:] = throw_a_coin(sample_size) == 'H'\n",
        "    return np.mean(start, axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {},
      "outputs": [],
      "source": [
        "throw_fractions = make_throws(number_of_samples=100, sample_size=500)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "So these are 100 samples of 500 coin tosses, in a situation where the coin is KNOWN to be fair, to be precise."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.hist(throw_fractions);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "As you can see, there are samples with as many as 56% heads in this experiment. \n",
        "\n",
        "What hapens if you increase the sample size?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {},
      "outputs": [],
      "source": [
        "throw_fractions = make_throws(number_of_samples=100, sample_size=1000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.hist(throw_fractions);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This is a tighter histogram as you might expect! More coin tosses in a sample, less the uncertainty due to sampling.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "So now imagine that the lord knew the population of Colorado, and said that 81% (and the lord knows who arethe exact 81%) will vote for Obama. \n",
        "\n",
        "But the lord has not told us what is going on with the people of the state.\n",
        "\n",
        "So Predictwise (or pollsters) have sampled only 1000 people (its expensive), and used that estimate to come up with a number of simulations in which Obama wins.\n",
        "\n",
        "And if different pollsters sample 1000 different people they will come up with different answers. Thus there is sampling error we suffer from. It propagates as slightly different probabilities that we need to account for. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Misspecification Error"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "As Box said \"All models are bad, but some are useful\". An predictor, such as Nate Silver might construct a complex model for the probability in a state, which partially takes into account polls in the state, and which partially uses economic indicators in a regression model. There is no saying that this is the true lord givem model for how I will vote. So there will be an error that occurs because of this misspecification. This error is hard to model because we dont actually know the true model, the lord given one. We can only sniff at it by sampling and trying different models and seeing how goos our predictions are."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Noise\n",
        "\n",
        "Finally there is always noise. You are trying to predict my voting pattern but you do not know my financial situation. My stressors. My marital status. My family. Two people of the same race, with same income might vote very differently because of these factors. This might be throught of as an incomplete model, but the point here is that only the lord knows this info, not you and I. So in a sense its indistinguishable from modeling error.\n",
        "\n",
        "These latter too errors would still be present if you gave me an infinite population, because they represent fundamentals of lack of knowledge and not being the lord. Sampling adds another dimension to it, you cant even get the full diversity of information you have in the population. But on a sample, its easy for all 3 of these errors to mix."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "So how do we deal with these problems? The simplest answer is that we wont for now, and the predictions we will make for Obama will thus be in a sense 'more precise\" than if I knew the ange of probabilities that come from many samples. But you can account for some of these effects: indeed pollsters will typically quote you a margin of error..this includes their estimate of sampling error (using a binomial distribution), their idea of systematic error (we called too many people on cell phones and thus missed old people), and their notion on noise. Ther are not usually fiddling with a regression model so dont deal with mis-specification error. But people like Nate Silver will try and fold it in with error propagation in regressions. \n",
        "\n",
        "Still, we are in the business of statistical models, and wont account for everything. So we always try and be conservative in our predictions. For instance in Colorado, if we are 80% likely to have Obama win, a lot of these effects might move us between 75 and 85, so our overall prediction does not really change. But our confidence in it does and we report that. "
      ]
    }
  ]
}